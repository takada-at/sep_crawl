{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sep.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takada-at/sep_crawl/blob/master/sep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrkgD7DQf8td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title クローラーの準備\n",
        "% cd /content\n",
        "! if [ ! -d sep_crawl ]; then git clone https://github.com/takada-at/sep_crawl.git; fi\n",
        "% cd sep_crawl\n",
        "! git pull\n",
        "! pip install -r requirements-colab.txt\n",
        "! mkdir -p data/sep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YJdX0x5sgS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title SEP記事のダウンロード\n",
        "# @markdown 80分程度かかります。\n",
        "% cd /content/sep_crawl/sep/\n",
        "! if [ -d ../data/sep ]; then rm -r ../data/sep; fi\n",
        "! time scrapy crawl entry --loglevel=INFO\n",
        "! cat ../data/sep/text/*.txt > ../data/sep/sep-entries.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXxgJE7qwUzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title ダウンロードしたファイルの確認\n",
        "# 行数\n",
        "! wc -l /content/sep_crawl/data/sep/sep-entries.txt \n",
        "! head /content/sep_crawl/data/sep/sep-entries.txt \n",
        "# ダウンロードした記事の確認\n",
        "! ls /content/sep_crawl/data/sep/text | head\n",
        "! ls /content/sep_crawl/data/sep/text | tail\n",
        "! ls /content/sep_crawl/data/sep/text | wc -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AesKzS2VEh7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title Google Driveにバックアップ\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "% cd /content\n",
        "! if [ -d sep-entries ]; then rm -r sep-entries; fi\n",
        "! mkdir sep-entries\n",
        "! if [ -f sep-entries.zip ]; then rm sep-entries.zip; fi\n",
        "! cp /content/sep_crawl/data/sep/sep-entries.txt sep-entries/\n",
        "! zip /content/sep-entries.zip sep-entries/*\n",
        "! cp /content/sep-entries.zip \"/content/drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVkKuEjyFas-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title Google Driveからインポート\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',  force_remount=True)\n",
        "! cp \"/content/drive/My Drive/sep-entries.zip\" /content/sep-entries.zip \n",
        "% cd /content\n",
        "! unzip sep-entries.zip\n",
        "! mv sep-entries/sep-entries.txt /content/sep_crawl/data/sep/sep-entries.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7k0LkG-Wo9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title word2vecモデルの作成\n",
        "from datetime import datetime\n",
        "from gensim.models.word2vec import LineSentence\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "sentences = LineSentence('/content/sep_crawl/data/sep/sep-entries.txt')\n",
        "s = datetime.now()\n",
        "w2v = Word2Vec(sentences, size=300)\n",
        "e = datetime.now()\n",
        "print('create word2vec model: {}'.format(e - s))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRzMZfGbMOuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title 単語ベクトルの確認\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(len(w2v.wv.vocab))\n",
        "words = np.array(tuple(w2v.wv.vocab.keys()))\n",
        "print(w2v.wv.most_similar_cosmul(positive=[\"kant\"], topn=3))\n",
        "# [('hegel', 0.7388843894004822),\n",
        "# ('hume', 0.7110885381698608),\n",
        "# ('spinoza', 0.6922929286956787)]\n",
        "\n",
        "print(w2v.wv.most_similar_cosmul(positive=[\"paris\", \"germany\"], negative=['france'], topn=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg4ZazwLCq5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "terms = ['kant']\n",
        "clusters = [0]\n",
        "n = 5\n",
        "for i in range(15):\n",
        "  result = w2v.wv.most_similar_cosmul(positive=terms, topn=n)\n",
        "  terms += [r[0] for r in result]\n",
        "  clusters += [i + 1] * n\n",
        "vectors = np.vstack([w2v.wv[t] for t in terms])\n",
        "print(terms)\n",
        "\n",
        "tsne = TSNE(n_components=2, perplexity=50.0)\n",
        "matrix = np.vstack(vectors)\n",
        "v2d = tsne.fit_transform(matrix)\n",
        "x = v2d[:, 0]\n",
        "y = v2d[:, 1]\n",
        "plt.figure(figsize=(12, 10))\n",
        "s = plt.scatter(x, y, c=clusters, cmap='viridis')\n",
        "plt.colorbar(s)\n",
        "plt.grid(True)\n",
        "for i, n in enumerate(terms):\n",
        "  plt.annotate(n, xy=(x[i], y[i]),\n",
        "                     xytext=(5, 2),\n",
        "                     textcoords='offset points',\n",
        "                     ha='right',\n",
        "                     va='bottom')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}